import os
import sys
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import csv
import io
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors
from reportlab.lib.units import inch
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend

# Importer l'analyseur SART depuis le module principal
# Si ce code est dans un fichier séparé, assurez-vous que le module SARTAnalyzer est dans le chemin Python
try:
    from sart_analysis import SARTAnalyzer
except ImportError:
    print("Erreur: Impossible d'importer la classe SARTAnalyzer.")
    print("Assurez-vous que le fichier sart_analysis.py est dans le même répertoire.")
    sys.exit(1)

def detect_csv_format(file_path):
    """
    Détecte automatiquement le format du fichier CSV (séparateur, encodage, etc.)

    Paramètres:
    -----------
    file_path : str
        Chemin vers le fichier CSV

    Retourne:
    ---------
    dict
        Dictionnaire avec les paramètres détectés (separator, encoding, decimal)
    """
    # Essayer différents encodages
    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
    for encoding in encodings:
        try:
            # Lire les premières lignes pour détecter le séparateur
            with open(file_path, 'r', encoding=encoding) as f:
                sample = ''.join([f.readline() for _ in range(5)])

            # Compter les occurrences de séparateurs potentiels
            separators = [',', ';', '\t', '|']
            sep_counts = {sep: sample.count(sep) for sep in separators}

            # Choisir le séparateur le plus fréquent
            detected_sep = max(sep_counts, key=sep_counts.get)

            # Détection du séparateur décimal
            decimal = ',' if detected_sep == ';' else '.'

            print(f"Format CSV détecté: séparateur='{detected_sep}', encodage='{encoding}', décimal='{decimal}'")
            return {
                'separator': detected_sep,
                'encoding': encoding,
                'decimal': decimal
            }
        except Exception:
            continue

    # Par défaut, si aucune détection n'a fonctionné
    print("Impossible de détecter automatiquement le format. Utilisation des paramètres par défaut.")
    return {
        'separator': ',',
        'encoding': 'utf-8',
        'decimal': '.'
    }

def guess_column_mapping(df):
    """
    Essaie de deviner les correspondances entre les colonnes du fichier et les noms standards

    Paramètres:
    -----------
    df : pandas.DataFrame
        DataFrame contenant les données

    Retourne:
    ---------
    dict
        Dictionnaire de correspondance des colonnes {nom_original: nom_standard}
    """
    mapping = {}

    # Mots-clés pour chaque type de colonne
    keywords = {
        'stimulus': ['stimulus', 'chiffre', 'digit', 'stim', 'nombre', 'number', 'cible', 'target'],
        'response': ['response', 'reponse', 'réponse', 'resp', 'key', 'touche', 'bouton', 'button'],
        'reaction_time': ['reaction_time', 'rt', 'temps', 'time', 'reaction', 'latence', 'latency', 'ms']
    }

    # Rechercher des correspondances approximatives dans les noms de colonnes
    for col in df.columns:
        col_lower = str(col).lower().strip()
        for standard_name, kw_list in keywords.items():
            for keyword in kw_list:
                if keyword in col_lower:
                    mapping[col] = standard_name
                    print(f"Correspondance détectée: '{col}' -> '{standard_name}'")
                    break

    # Vérifier si nous avons manqué des colonnes essentielles
    missing_cols = set(['stimulus', 'response', 'reaction_time']) - set(mapping.values())
    if missing_cols:
        print(f"Avertissement: Colonnes essentielles non détectées: {', '.join(missing_cols)}")

    # Essayer de faire des suppositions basées sur le type et contenu des colonnes
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

    # Si nous n'avons pas identifié la colonne stimulus
    if 'stimulus' not in mapping.values() and numeric_cols:
        # Chercher une colonne avec peu de valeurs uniques qui pourrait être un stimulus
        for col in numeric_cols:
            if df[col].nunique() < 10 and col not in mapping.keys():  # Typiquement peu de stimuli différents
                mapping[col] = 'stimulus'
                print(f"Supposition: '{col}' pourrait être 'stimulus' (peu de valeurs uniques)")
                break

    # Si nous n'avons pas identifié la colonne reaction_time
    if 'reaction_time' not in mapping.values() and numeric_cols:
        # Chercher une colonne à valeurs numériques élevées qui pourrait être RT
        for col in numeric_cols:
            if df[col].median() > 100 and col not in mapping.keys():  # Les RT sont généralement > 100ms
                mapping[col] = 'reaction_time'
                print(f"Supposition: '{col}' pourrait être 'reaction_time' (valeurs typiques de RT)")
                break

    # Si nous n'avons pas identifié la colonne response
    if 'response' not in mapping.values():
        # Chercher une colonne qui pourrait contenir des réponses
        for col in df.columns:
            if col not in mapping.keys():
                unique_vals = df[col].nunique()
                if 1 <= unique_vals <= 5:  # Généralement peu de touches de réponse
                    mapping[col] = 'response'
                    print(f"Supposition: '{col}' pourrait être 'response' (peu de réponses uniques)")
                    break

    return mapping

def generate_pdf_report(analyzer, output_file, figures=None):
    """
    Génère un rapport PDF détaillé des résultats de l'analyse SART

    Paramètres:
    -----------
    analyzer : SARTAnalyzer
        Instance de l'analyseur SART contenant les résultats
    output_file : str
        Chemin vers le fichier PDF de sortie
    figures : list, optional
        Liste des figures matplotlib à inclure dans le rapport
    """
    print(f"Génération du rapport PDF: {output_file}")
    
    # Créer le document PDF
    doc = SimpleDocTemplate(output_file, pagesize=letter)
    styles = getSampleStyleSheet()
    
    # Créer des styles personnalisés
    styles.add(ParagraphStyle(name='Title', 
                              parent=styles['Heading1'], 
                              fontSize=18, 
                              alignment=1,
                              spaceAfter=12))
    
    styles.add(ParagraphStyle(name='Subtitle', 
                              parent=styles['Heading2'], 
                              fontSize=14, 
                              spaceAfter=10))
    
    styles.add(ParagraphStyle(name='Section', 
                              parent=styles['Heading3'], 
                              fontSize=12, 
                              spaceAfter=8))
    
    # Contenu du rapport
    content = []
    
    # Titre du rapport
    content.append(Paragraph("Rapport d'analyse SART", styles['Title']))
    content.append(Paragraph(f"Généré le {datetime.now().strftime('%d/%m/%Y à %H:%M')}", styles['Normal']))
    content.append(Spacer(1, 0.2*inch))
    
    # 1. Résumé des résultats
    content.append(Paragraph("1. Résumé des résultats", styles['Subtitle']))
    
    # Tableau des métriques principales
    results = analyzer.results
    data = [
        ["Métrique", "Valeur"],
        ["Précision globale", f"{results.get('accuracy', 'N/A'):.2%}"],
        ["Erreurs de commission", f"{results.get('commission_error_rate', 'N/A'):.2%}"],
        ["Erreurs d'omission", f"{results.get('omission_error_rate', 'N/A'):.2%}"],
        ["Temps de réaction moyen", f"{results.get('mean_rt', 'N/A'):.2f} ms"],
        ["d' (sensibilité)", f"{results.get('d_prime', 'N/A'):.2f}"],
        ["Biais de réponse (β)", f"{results.get('beta', 'N/A'):.2f}"],
        ["Variabilité des TR", f"{results.get('rt_variability', 'N/A'):.2f} ms"]
    ]
    
    t = Table(data, colWidths=[2.5*inch, 2.5*inch])
    t.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (1, 0), 'CENTER'),
        ('FONTNAME', (0, 0), (1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (1, 0), 12),
        ('BACKGROUND', (0, 1), (1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black),
        ('ALIGN', (1, 1), (1, -1), 'RIGHT'),
    ]))
    
    content.append(t)
    content.append(Spacer(1, 0.2*inch))
    
    # 2. Interprétation
    content.append(Paragraph("2. Interprétation des résultats", styles['Subtitle']))
    
    # Interprétation de la précision
    accuracy = results.get('accuracy', 0)
    if accuracy > 0.9:
        acc_interpretation = "Excellente précision globale, suggérant un bon niveau d'attention soutenue."
    elif accuracy > 0.8:
        acc_interpretation = "Bonne précision globale, niveau d'attention soutenue satisfaisant."
    elif accuracy > 0.7:
        acc_interpretation = "Précision moyenne, des difficultés d'attention soutenue possibles."
    else:
        acc_interpretation = "Précision faible, suggérant des difficultés importantes d'attention soutenue."
    
    content.append(Paragraph("<b>Précision globale:</b> " + acc_interpretation, styles['Normal']))
    content.append(Spacer(1, 0.1*inch))
    
    # Interprétation des erreurs de commission
    commission = results.get('commission_error_rate', 0)
    if commission < 0.05:
        com_interpretation = "Très peu d'erreurs de commission, suggérant un bon contrôle de l'inhibition."
    elif commission < 0.15:
        com_interpretation = "Taux d'erreurs de commission modéré, contrôle de l'inhibition satisfaisant."
    elif commission < 0.25:
        com_interpretation = "Taux d'erreurs de commission élevé, des difficultés de contrôle de l'inhibition possibles."
    else:
        com_interpretation = "Taux d'erreurs de commission très élevé, suggérant des difficultés importantes de contrôle de l'inhibition."
    
    content.append(Paragraph("<b>Erreurs de commission:</b> " + com_interpretation, styles['Normal']))
    content.append(Spacer(1, 0.1*inch))
    
    # Interprétation d'omission
    omission = results.get('omission_error_rate', 0)
    if omission < 0.05:
        om_interpretation = "Très peu d'erreurs d'omission, suggérant une bonne vigilance."
    elif omission < 0.15:
        om_interpretation = "Taux d'erreurs d'omission modéré, niveau de vigilance satisfaisant."
    elif omission < 0.25:
        om_interpretation = "Taux d'erreurs d'omission élevé, des difficultés de vigilance possibles."
    else:
        om_interpretation = "Taux d'erreurs d'omission très élevé, suggérant des difficultés importantes de vigilance."
    
    content.append(Paragraph("<b>Erreurs d'omission:</b> " + om_interpretation, styles['Normal']))
    content.append(Spacer(1, 0.1*inch))
    
    # Interprétation du d'
    dprime = results.get('d_prime', 0)
    if dprime > 3:
        d_interpretation = "Excellente sensibilité (d' élevé), suggérant une bonne discrimination entre les stimuli."
    elif dprime > 2:
        d_interpretation = "Bonne sensibilité (d'), discrimination satisfaisante entre les stimuli."
    elif dprime > 1:
        d_interpretation = "Sensibilité moyenne (d'), certaines difficultés de discrimination possibles."
    else:
        d_interpretation = "Faible sensibilité (d' bas), suggérant des difficultés importantes de discrimination."
    
    content.append(Paragraph("<b>Sensibilité (d'):</b> " + d_interpretation, styles['Normal']))
    content.append(Spacer(1, 0.1*inch))
    
    # Interprétation de la variabilité des TR
    rtcv = results.get('rt_cv', 0) * 100  # Coefficient de variation en pourcentage
    if rtcv < 15:
        rtcv_interpretation = "Faible variabilité des temps de réaction, suggérant une performance stable."
    elif rtcv < 25:
        rtcv_interpretation = "Variabilité modérée des temps de réaction, stabilité de la performance acceptable."
    elif rtcv < 35:
        rtcv_interpretation = "Variabilité élevée des temps de réaction, indiquant une instabilité possible de l'attention."
    else:
        rtcv_interpretation = "Très forte variabilité des temps de réaction, suggérant une instabilité importante de l'attention."
    
    content.append(Paragraph("<b>Variabilité des temps de réaction:</b> " + rtcv_interpretation, styles['Normal']))
    content.append(Spacer(1, 0.2*inch))
    
    # 3. Intégration des figures
    if figures:
        content.append(Paragraph("3. Visualisations des données", styles['Subtitle']))
        
        for i, fig in enumerate(figures):
            # Sauvegarder la figure dans un buffer temporaire
            buf = io.BytesIO()
            fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')
            buf.seek(0)
            
            # Ajouter une image au document
            img = Image(buf, width=6*inch, height=4*inch)
            content.append(img)
            
            # Ajouter une légende
            if i == 0:
                caption = "Figure 1: Métriques de base de la performance SART"
            elif i == 1:
                caption = "Figure 2: Métriques avancées de l'attention soutenue"
            elif i == 2:
                caption = "Figure 3: Effets séquentiels sur la performance"
            elif i == 3:
                caption = "Figure 4: Distribution des temps de réaction"
            else:
                caption = f"Figure {i+1}"
            
            content.append(Paragraph(caption, styles['Caption']))
            content.append(Spacer(1, 0.2*inch))
    
    # 4. Conclusions et recommandations
    content.append(Paragraph("4. Conclusions et recommandations", styles['Subtitle']))
    
    # Évaluation globale
    if accuracy > 0.85 and commission < 0.15 and dprime > 2:
        overall = "L'analyse des résultats SART suggère un excellent niveau d'attention soutenue et un bon contrôle de l'inhibition. "
        recomm = "Aucune intervention spécifique n'est recommandée sur la base de ces résultats."
    elif accuracy > 0.75 and commission < 0.25 and dprime > 1.5:
        overall = "L'analyse des résultats SART suggère un niveau satisfaisant d'attention soutenue avec quelques faiblesses mineures dans le contrôle de l'inhibition. "
        recomm = "Des exercices modérés d'attention pourraient être bénéfiques pour améliorer davantage les performances."
    elif accuracy > 0.65 and commission < 0.35 and dprime > 1:
        overall = "L'analyse des résultats SART suggère certaines difficultés d'attention soutenue et de contrôle de l'inhibition. "
        recomm = "Des exercices réguliers d'attention et de contrôle cognitif pourraient être bénéfiques. Une évaluation plus approfondie pourrait être envisagée si ces difficultés impactent la vie quotidienne."
    else:
        overall = "L'analyse des résultats SART suggère des difficultés importantes d'attention soutenue et de contrôle de l'inhibition. "
        recomm = "Une évaluation plus approfondie par un spécialiste est recommandée pour explorer ces difficultés et proposer des interventions adaptées."
    
    content.append(Paragraph(overall, styles['Normal']))
    content.append(Spacer(1, 0.1*inch))
    content.append(Paragraph("<b>Recommandations:</b> " + recomm, styles['Normal']))
    
    # Ajouter le contenu au document et générer le PDF
    doc.build(content)
    
    return output_file

def analyze_sart_csv(input_file, output_dir=None, target_value=None, column_mapping=None, generate_pdf=True):
    """
    Analyser un fichier CSV contenant des données SART et générer un rapport complet

    Paramètres:
    -----------
    input_file : str
        Chemin vers le fichier CSV d'entrée
    output_dir : str, optional
        Répertoire de sortie pour les résultats. Par défaut, utilise le même répertoire que le fichier d'entrée
    target_value : any, optional
        Valeur qui identifie un stimulus comme étant une cible
    column_mapping : dict, optional
        Dictionnaire de correspondance personnalisé pour les noms de colonnes
    generate_pdf : bool, optional
        Si True, génère un rapport PDF en plus des autres formats

    Retourne:
    ---------
    tuple
        (analyzer, results_file, report_file, figures) - L'analyseur, les chemins vers les fichiers de résultats et de rapport,
        et la liste des figures générées
    """
    print(f"\n{'='*60}")
    print(f"ANALYSE SART: {os.path.basename(input_file)}")
    print(f"{'='*60}\n")

    # Vérifier que le fichier existe
    if not os.path.exists(input_file):
        raise FileNotFoundError(f"Le fichier {input_file} n'existe pas.")

    # Vérifier que le fichier est bien un CSV
    file_ext = os.path.splitext(input_file)[1].lower()
    if file_ext != '.csv':
        print(f"Avertissement: Le fichier n'a pas l'extension .csv ({file_ext})")

    # Vérifier si le contenu ressemble à un CSV
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            first_line = f.readline().strip()
            if ',' not in first_line and ';' not in first_line and '\t' not in first_line:
                print("Le contenu ne semble pas être au format CSV.")
                cont = input("Voulez-vous continuer quand même? (o/n): ")
                if cont.lower() != 'o':
                    sys.exit(0)
    except Exception as e:
        print(f"Erreur lors de la vérification du contenu du fichier: {e}")

    # Déterminer le répertoire de sortie
    if output_dir is None:
        output_dir = os.path.dirname(input_file)
        if not output_dir:
            output_dir = "."

    # Créer le répertoire de sortie s'il n'existe pas
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    print(f"Répertoire de sortie créé: {output_dir}")

    # Nom de base pour les fichiers de sortie
    base_name = os.path.splitext(os.path.basename(input_file))[0]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Détecter le format du CSV
    print("\n1. Détection du format CSV...")
    csv_params = detect_csv_format(input_file)

    # Initialiser l'analyseur et charger le fichier
    print("\n2. Chargement des données...")
    analyzer = SARTAnalyzer()

    # Tenter de charger le fichier avec les paramètres détectés
    try:
        df = pd.read_csv(
            input_file,
            sep=csv_params['separator'],
            encoding=csv_params['encoding'],
            decimal=csv_params['decimal']
        )
        analyzer.data = df
        print(f"Fichier chargé avec succès: {len(df)} lignes, {len(df.columns)} colonnes")

        # Afficher un aperçu des données
        print("\nAperçu des données:")
        print(df.head(3).to_string())

        # Afficher les informations sur les colonnes
        print("\nInformations sur les colonnes:")
        for col in df.columns:
            unique_vals = df[col].nunique()
            data_type = df[col].dtype
            print(f" - {col}: {unique_vals} valeurs uniques, type: {data_type}")

        # Si aucun mapping de colonnes n'est fourni, essayer de le deviner
        if column_mapping is None:
            print("\n3. Détection automatique des colonnes...")
            column_mapping = guess_column_mapping(df)

        # Afficher le mapping trouvé
        print("\nCorrespondance des colonnes détectée:")
        for orig, std in column_mapping.items():
            print(f" - {orig} -> {std}")

        # Vérifier si toutes les colonnes nécessaires ont été identifiées
        required_cols = {'stimulus', 'response', 'reaction_time'}
        found_cols = set(column_mapping.values())
        missing = required_cols - found_cols
        if missing:
            print(f"\nATTENTION: Colonnes requises non identifiées: {', '.join(missing)}")
            print("Vous devez spécifier manuellement le mapping des colonnes avec l'option --column-mapping")
            print("Exemple: --column-mapping 'colonne1:stimulus' 'colonne2:response' 'colonne3:reaction_time'")
            cont = input("Voulez-vous continuer avec le mapping partiel détecté? (o/n): ")
            if cont.lower() != 'o':
                sys.exit(0)

    except Exception as e:
        print(f"\nERREUR: {e}")
        print("\nConseil de débogage:")
        print("1. Vérifiez le format de votre fichier CSV et assurez-vous qu'il contient bien les données SART.")
        print("2. Les colonnes essentielles sont: stimulus, response, reaction_time.")
        print("3. Utilisez les options --csv-separator, --csv-encoding et --csv-decimal pour spécifier le format.")
        print("4. Utilisez l'option --interactive pour un guidage étape par étape.")
        sys.exit(1)

    # Prétraiter les données
    print("\n4. Prétraitement des données...")
    try:
        analyzer.preprocess_data(target_stimulus=target_value, column_mapping=column_mapping)
    except Exception as e:
        print(f"Erreur lors du prétraitement: {e}")
        
        # Si le prétraitement échoue, afficher des informations utiles pour le débogage
        print("\nContenu des colonnes détectées:")
        for std_name, orig_name in {v: k for k, v in column_mapping.items()}.items():
            if orig_name in analyzer.data.columns:
                unique_vals = analyzer.data[orig_name].unique()[:5]
                print(f" - {std_name} ('{orig_name}'): {unique_vals}")

        # Essayer de déterminer automatiquement la valeur cible si non spécifiée
        if target_value is None and 'stimulus' in column_mapping.values():
            stim_col = [k for k, v in column_mapping.items() if v == 'stimulus'][0]
            unique_stims = analyzer.data[stim_col].unique()
            print(f"\nValeurs uniques de stimulus: {unique_stims}")
            
            if len(unique_stims) > 1 and len(unique_stims) < 10:
                # Supposer que la valeur la moins fréquente est la cible
                counts = analyzer.data[stim_col].value_counts()
                least_common = counts.idxmin()
                print(f"Suggestion: la valeur '{least_common}' pourrait être la cible (la moins fréquente)")
                
                use_suggestion = input(f"Utiliser '{least_common}' comme valeur cible? (o/n): ")
                if use_suggestion.lower() == 'o':
                    target_value = least_common
                    
                    # Réessayer le prétraitement avec la nouvelle valeur cible
                    try:
                        analyzer.preprocess_data(target_stimulus=target_value, column_mapping=column_mapping)
                        print(f"Succès avec la valeur cible = {target_value}")
                    except Exception as e2:
                        print(f"Échec même avec la valeur cible suggérée: {e2}")
                        sys.exit(1)
                else:
                    sys.exit(1)
            else:
                sys.exit(1)
        else:
            sys.exit(1)

    # Calculer les métriques
    print("\n5. Calcul des métriques...")
    analyzer.calculate_basic_metrics()
    analyzer.calculate_advanced_metrics()

    # Analyser les effets temporels et séquentiels
    print("\n6. Analyse des effets temporels et séquentiels...")
    try:
        # Déterminer la taille de fenêtre basée sur le nombre d'essais
        window_size = max(10, int(len(analyzer.data) * 0.1))  # 10% des essais ou au moins 10
        
        analyzer.analyze_time_on_task_effects(window_size=window_size)
        analyzer.analyze_sequential_effects(n_back=1)
    except Exception as e:
        print(f"Avertissement: Impossible d'analyser les effets temporels/séquentiels: {e}")

    # Générer les résultats et rapports
    print("\n7. Génération des résultats et rapports...")
    
    # Fichier JSON des résultats
    results_file = os.path.join(output_dir, f"{base_name}_results_{timestamp}.json")
    analyzer.export_results(results_file)
    print(f"Résultats exportés vers: {results_file}")

    # Rapport détaillé au format Markdown
    report_file = os.path.join(output_dir, f"{base_name}_report_{timestamp}.md")
    analyzer.generate_report(report_file)
    print(f"Rapport généré vers: {report_file}")

    # Générer les visualisations
    print("\n8. Génération des visualisations...")
    figures = []

    try:
        # Métriques de base
        fig1 = analyzer.plot_basic_metrics()
        figures.append(fig1)
        basic_fig_file = os.path.join(output_dir, f"{base_name}_basic_metrics_{timestamp}.png")
        fig1.savefig(basic_fig_file, dpi=100, bbox_inches='tight')
        print(f"Graphique des métriques de base enregistré: {basic_fig_file}")

        # Métriques avancées
        fig2 = analyzer.plot_advanced_metrics()
        figures.append(fig2)
        adv_fig_file = os.path.join(output_dir, f"{base_name}_advanced_metrics_{timestamp}.png")
        fig2.savefig(adv_fig_file, dpi=100, bbox_inches='tight')
        print(f"Graphique des métriques avancées enregistré: {adv_fig_file}")

        # Effets séquentiels
        fig3 = analyzer.plot_sequential_effects()
        figures.append(fig3)
        seq_fig_file = os.path.join(output_dir, f"{base_name}_sequential_effects_{timestamp}.png")
        fig3.savefig(seq_fig_file, dpi=100, bbox_inches='tight')
        print(f"Graphique des effets séquentiels enregistré: {seq_fig_file}")

        # Distribution des temps de réaction
        try:
            fig4 = plt.figure(figsize=(10, 6))
            rt_col = [k for k, v in column_mapping.items() if v == 'reaction_time'][0]
            valid_rts = analyzer.data[rt_col].dropna()
            
            plt.hist(valid_rts, bins=30, alpha=0.7, color='blue
